{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgAM4+Lt/j45G4p2GTbW+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/megsdata/sEMG_SupervisedLearning/blob/main/23Jul10_reloading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTExq-PzTUlb",
        "outputId": "b0365175-3d06-495e-fc8d-1701c801a7fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import os\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import weightwatcher as ww\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
        "np.set_printoptions(precision=4)\n",
        "print(tf.version.VERSION)\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install WeightWatcher"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXUpjbXSTn1H",
        "outputId": "230e7570-48db-4a08-be12-e0ef71a8f92d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting WeightWatcher\n",
            "  Downloading weightwatcher-0.7.1.5-py3-none-any.whl (69 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/69.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from WeightWatcher) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from WeightWatcher) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from WeightWatcher) (3.7.1)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from WeightWatcher) (0.1.6)\n",
            "Collecting powerlaw (from WeightWatcher)\n",
            "  Downloading powerlaw-1.5-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from WeightWatcher) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from WeightWatcher) (4.65.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->WeightWatcher) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->WeightWatcher) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->WeightWatcher) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->WeightWatcher) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->WeightWatcher) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->WeightWatcher) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->WeightWatcher) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->WeightWatcher) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline->WeightWatcher) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->WeightWatcher) (2022.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from powerlaw->WeightWatcher) (1.10.1)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.10/dist-packages (from powerlaw->WeightWatcher) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->WeightWatcher) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->WeightWatcher) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->WeightWatcher) (1.16.0)\n",
            "Installing collected packages: powerlaw, WeightWatcher\n",
            "Successfully installed WeightWatcher-0.7.1.5 powerlaw-1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(ww.__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "checkpoint_path = \"logs/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "metadata": {
        "id": "6Q9wS6qWUBSL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/MSC_THESIS/')\n",
        "%cd /MSC_THESIS/MyDrive/School - Ryerson Graduate/MSC_THESIS/23Jul09_Envelope_DL_Data\n",
        "import pathlib\n",
        "all_files =  sorted(str(p) for p in pathlib.Path('/MSC_THESIS/MyDrive/School - Ryerson Graduate/MSC_THESIS/23Jul09_Envelope_DL_Data/').glob(\"*.csv\"))\n",
        "#print(all_files)\n",
        "df = pd.read_csv(\"/MSC_THESIS/MyDrive/School - Ryerson Graduate/MSC_THESIS/23Jul09_Envelope_DL_Data/_11_MATRIX.csv\")\n",
        "for i in range(len(all_files)-1):\n",
        "  temp = pd.read_csv(all_files[i])\n",
        "  df = pd.concat([df, temp], axis=0)\n",
        "  #print(len(df.index))\n",
        "df['ContractionDuration'] = df['Contraction End Time (s)'] - df['Contraction Start Time(s)']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S0x_OuUbqtx",
        "outputId": "582fd8cd-d4d2-4bba-a265-8f3c0ab2b96a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /MSC_THESIS/\n",
            "/MSC_THESIS/MyDrive/School - Ryerson Graduate/MSC_THESIS/23Jul09_Envelope_DL_Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_prep(my_state):\n",
        "  #select features\n",
        "  X = df[['Trial Type', 'ContractionDuration', 'Pulse Width', \\\n",
        "          'Contraction Start Time(s)', 'Contraction End Time (s)', 'ContractionNo', \\\n",
        "          'Sex', 'Age', 'Height', 'Weight', 'Previous Injury', 'Fibula Length', 'Shank Girth', \\\n",
        "          'Time(s)', 'EMG(mv)', 'MMG_x', 'MMG_y', 'MMG_z', 'ContractionDuration'\n",
        "          ]]\n",
        "  y = df['Pain Label']\n",
        "  #create data split\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=my_state)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=my_state)\n",
        "  print(\"Number of samples in the training set: \", len(X_train))\n",
        "  print(\"Number of samples in the test set: \", len(X_test))\n",
        "  print(\"Number of samples in the validation set: \", len(X_val))\n",
        "  #scale the data\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "  X_val_scaled = scaler.transform(X_val)\n",
        "  return X_train_scaled, X_test_scaled, X_val_scaled, y_train, y_test, y_val"
      ],
      "metadata": {
        "id": "1NPsfvA-UEKF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_CNN_model(my_state, num_feat):\n",
        "  tf.random.set_seed(my_state)\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv1D(100, num_feat, activation='relu', name=\"convLayer\", input_shape=(num_feat, 1)),\n",
        "      tf.keras.layers.Dense(1024, activation='relu', name=\"relu1Layer\"),\n",
        "      #tf.keras.layers.Conv1D(100, num_feat, activation='relu', name=\"2ndconvLayer\", input_shape=(None, 1, 100000)),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu2Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu3Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu4Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu5Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu6Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu7Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu8Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu9Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu10Layer\"),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid', name=\"sigmoidLayer\")\n",
        "      #tf.keras.layers.Dense(1, activation='relu', name=\"sigmoidLayer\")\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        tf.keras.metrics.BinaryCrossentropy(name='binary cross entropy'),\n",
        "        tf.keras.metrics.BinaryIoU(name='binary IoU')\n",
        "    ]\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def create_LSTM_model(my_state, num_feat):\n",
        "  tf.random.set_seed(my_state)\n",
        "  model = tf.keras.Sequential([\n",
        "      #tf.keras.layers.LSTM(128, input_shape=(num_feat, 1)),\n",
        "      tf.keras.layers.LSTM(256, input_shape=(num_feat, 1)),\n",
        "      tf.keras.layers.Dense(128, activation='relu', name=\"relu1Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu2Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu3Layer\"),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid', name=\"sigmoidLayer\")\n",
        "  ])\n",
        "  model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        tf.keras.metrics.BinaryCrossentropy(name='binary cross entropy'),\n",
        "        tf.keras.metrics.BinaryIoU(name='binary IoU')\n",
        "    ]\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def create_regularized_LSTM_model(my_state, factor, rate, num_feat):\n",
        "  tf.random.set_seed(my_state)\n",
        "  model = tf.keras.Sequential([\n",
        "      #Dropout(rate),\n",
        "      tf.keras.layers.LSTM(256, input_shape=(num_feat, 1)),\n",
        "      #Dropout(rate),\n",
        "      #tf.keras.layers.LSTM(128, input_shape=(None, 1, 256)),\n",
        "      Dropout(rate),\n",
        "      tf.keras.layers.Dense(128, kernel_regularizer=l2(factor), activation='relu', name=\"relu1Layer\"),\n",
        "      Dropout(rate),\n",
        "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu2Layer\"),\n",
        "      Dropout(rate),\n",
        "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu3Layer\"),\n",
        "      Dropout(rate),\n",
        "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu4Layer\"),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid', name=\"sigmoidLayer\")\n",
        "      #tf.keras.layers.Dense(1, activation='relu', name=\"reluLayer\")\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.binary_crossentropy,\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "      metrics=[\n",
        "          tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "          tf.keras.metrics.Precision(name='precision'),\n",
        "          tf.keras.metrics.Recall(name='recall'),\n",
        "          tf.keras.metrics.BinaryCrossentropy(name='binary cross entropy'),\n",
        "          tf.keras.metrics.BinaryIoU(name='binary IoU')\n",
        "      ]\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def train_model(X_train_scaled, y_train, num_epochs):\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=checkpoint_dir, histogram_freq=1)\n",
        "  print(\"Training the neural network.. \")\n",
        "  history = model.fit(X_train_scaled, y_train, batch_size=32, epochs=num_epochs, callbacks=[cp_callback])\n",
        "  model.summary()\n",
        "  return history\n",
        "\n",
        "def visualize_performance(num_epochs, history):\n",
        "  import matplotlib.pyplot as plt\n",
        "  from matplotlib import rcParams\n",
        "  rcParams['figure.figsize'] = (18, 8)\n",
        "  rcParams['axes.spines.top'] = False\n",
        "  rcParams['axes.spines.right'] = False\n",
        "  plt.plot(\n",
        "      np.arange(1, num_epochs+1),\n",
        "      history.history['loss'], label='Loss'\n",
        "  )\n",
        "  plt.plot(\n",
        "      np.arange(1, num_epochs+1),\n",
        "      history.history['accuracy'], label='Accuracy'\n",
        "  )\n",
        "  plt.plot(\n",
        "      np.arange(1, num_epochs+1),\n",
        "      history.history['precision'], label='Precision'\n",
        "  )\n",
        "  plt.plot(\n",
        "      np.arange(1, num_epochs+1),\n",
        "      history.history['recall'], label='Recall'\n",
        "  )\n",
        "  plt.title('Evaluation metrics', size=20)\n",
        "  plt.xlabel('Epoch', size=14)\n",
        "  plt.legend();\n",
        "\n",
        "def evaluate_performance(model, X_test_scaled, y_test):\n",
        "  predictions = model.predict(X_test_scaled)\n",
        "  prediction_classes = [\n",
        "      1 if prob > 0.5 else 0 for prob in np.ravel(predictions)\n",
        "  ]\n",
        "  prediction_classes = [\n",
        "      1 if prob > 0.5 else 0 for prob in np.ravel(predictions)\n",
        "  ]\n",
        "  from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "  print(f'Accuracy: {accuracy_score(y_test, prediction_classes):.4f}')\n",
        "  print(f'Precision: {precision_score(y_test, prediction_classes):.4f}')\n",
        "  print(f'Recall: {recall_score(y_test, prediction_classes):.4f}')"
      ],
      "metadata": {
        "id": "JDlmwofnUR1T"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_state = 21\n",
        "num_epochs = 100\n",
        "X_train_scaled, X_test_scaled, X_val_scaled, y_train, y_test, y_val = data_prep(my_state)\n",
        "# Create a callback that saves the model's weights\n",
        "checkpoint_path = \"/MSC_THESIS/MyDrive/School - Ryerson Graduate/MSC_THESIS/logs/23Jul10_reload/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "model = create_regularized_LSTM_model(my_state, 1e-5, 0.3, 19) #model creation and compilation\n",
        "model.load_weights('/MSC_THESIS/MyDrive/School - Ryerson Graduate/MSC_THESIS/logs/23Jul09_Regularized_LSTM/cp-0097.ckpt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH0mQzkHTVJw",
        "outputId": "d681add5-e6e0-408f-b5e0-b539a8c98bf0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in the training set:  3240141\n",
            "Number of samples in the test set:  1012545\n",
            "Number of samples in the validation set:  810036\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f552390f160>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize_performance(num_epochs, history)\n",
        "evaluate_performance(model, X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtVXKg8FT4Qh",
        "outputId": "c5f08e0b-a515-4602-dd7d-cc7607090e7a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22609/31643 [====================>.........] - ETA: 3:20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31643/31643 [==============================] - 703s 22ms/step\n",
            "Accuracy: 0.9027\n",
            "Precision: 0.9049\n",
            "Recall: 0.9628\n"
          ]
        }
      ]
    }
  ]
}