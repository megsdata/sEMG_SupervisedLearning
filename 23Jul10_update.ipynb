{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrfEdOCTCC6MJcupD8dYEj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/megsdata/sEMG_SupervisedLearning/blob/main/23Jul10_update.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTExq-PzTUlb",
        "outputId": "61ee6bdc-d6bc-4def-e835-87396df2b016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import os\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import weightwatcher as ww\n",
        "import warnings\n",
        "import keras_tuner as kt\n",
        "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
        "np.set_printoptions(precision=4)\n",
        "print(tf.version.VERSION)\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install WeightWatcher\n",
        "!pip install keras-tuner --upgrade\n",
        "!pip install -q -U keras-tuner"
      ],
      "metadata": {
        "id": "sXUpjbXSTn1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(ww.__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "checkpoint_path = \"logs/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "metadata": {
        "id": "6Q9wS6qWUBSL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/MSC_THESIS/')\n",
        "%cd /MSC_THESIS/MyDrive/School - Ryerson Graduate/MSC_THESIS/23Jul09_Envelope_DL_Data\n",
        "import pathlib\n",
        "all_files =  sorted(str(p) for p in pathlib.Path('/MSC_THESIS/MyDrive/School - Ryerson Graduate/MSC_THESIS/23Jul09_Envelope_DL_Data/').glob(\"*.csv\"))\n",
        "#print(all_files)\n",
        "df = pd.read_csv(\"/MSC_THESIS/MyDrive/School - Ryerson Graduate/MSC_THESIS/23Jul09_Envelope_DL_Data/_11_MATRIX.csv\")\n",
        "for i in range(len(all_files)-1):\n",
        "  temp = pd.read_csv(all_files[i])\n",
        "  df = pd.concat([df, temp], axis=0)\n",
        "  #print(len(df.index))\n",
        "df['ContractionDuration'] = df['Contraction End Time (s)'] - df['Contraction Start Time(s)']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S0x_OuUbqtx",
        "outputId": "83b0e8f0-adbe-457e-c2ac-bd79c36b2d83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /MSC_THESIS/\n",
            "/MSC_THESIS/MyDrive/School - Ryerson Graduate/MSC_THESIS/23Jul09_Envelope_DL_Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_prep(my_state):\n",
        "  #select features\n",
        "  X = df[['Trial Type', 'ContractionDuration', 'Pulse Width', \\\n",
        "          'Contraction Start Time(s)', 'Contraction End Time (s)', 'ContractionNo', \\\n",
        "          'Sex', 'Age', 'Height', 'Weight', 'Previous Injury', 'Fibula Length', 'Shank Girth', \\\n",
        "          'Time(s)', 'EMG(mv)', 'MMG_x', 'MMG_y', 'MMG_z', 'ContractionDuration'\n",
        "          ]]\n",
        "  y = df['Pain Label']\n",
        "  #create data split\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=my_state)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=my_state)\n",
        "  print(\"Number of samples in the training set: \", len(X_train))\n",
        "  print(\"Number of samples in the test set: \", len(X_test))\n",
        "  print(\"Number of samples in the validation set: \", len(X_val))\n",
        "  #scale the data\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "  X_val_scaled = scaler.transform(X_val)\n",
        "  return X_train_scaled, X_test_scaled, X_val_scaled, y_train, y_test, y_val"
      ],
      "metadata": {
        "id": "1NPsfvA-UEKF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_FCNN_model(my_state, num_feat):\n",
        "  tf.random.set_seed(my_state)\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv1D(100, num_feat, activation='relu', name=\"convLayer\", input_shape=(num_feat, 1)),\n",
        "      tf.keras.layers.Dense(1024, activation='relu', name=\"relu1Layer\"),\n",
        "      #tf.keras.layers.Conv1D(100, num_feat, activation='relu', name=\"2ndconvLayer\", input_shape=(None, 1, 100000)),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu2Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu3Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu4Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu5Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu6Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu7Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu8Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu9Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu10Layer\"),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid', name=\"sigmoidLayer\")\n",
        "      #tf.keras.layers.Dense(1, activation='relu', name=\"sigmoidLayer\")\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        tf.keras.metrics.BinaryCrossentropy(name='binary cross entropy'),\n",
        "        tf.keras.metrics.BinaryIoU(name='binary IoU')\n",
        "    ]\n",
        "  )\n",
        "  return model\n",
        "\n",
        "\n",
        "def create_CNN_model(my_state, num_feat):\n",
        "  tf.random.set_seed(my_state)\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv1D(100, num_feat, activation='relu', name=\"convLayer\", input_shape=(num_feat, 1)),\n",
        "      tf.keras.layers.Dense(1024, activation='relu', name=\"relu1Layer\"),\n",
        "      #tf.keras.layers.Conv1D(100, num_feat, activation='relu', name=\"2ndconvLayer\", input_shape=(None, 1, 100000)),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu2Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu3Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu4Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu5Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu6Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu7Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu8Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu9Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu10Layer\"),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid', name=\"sigmoidLayer\")\n",
        "      #tf.keras.layers.Dense(1, activation='relu', name=\"sigmoidLayer\")\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        tf.keras.metrics.BinaryCrossentropy(name='binary cross entropy'),\n",
        "        tf.keras.metrics.BinaryIoU(name='binary IoU')\n",
        "    ]\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def create_LSTM_model(my_state, num_feat):\n",
        "  tf.random.set_seed(my_state)\n",
        "  model = tf.keras.Sequential([\n",
        "      #tf.keras.layers.LSTM(128, input_shape=(num_feat, 1)),\n",
        "      tf.keras.layers.LSTM(256, input_shape=(num_feat, 1)),\n",
        "      tf.keras.layers.Dense(128, activation='relu', name=\"relu1Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu2Layer\"),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name=\"relu3Layer\"),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid', name=\"sigmoidLayer\")\n",
        "  ])\n",
        "  model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        tf.keras.metrics.BinaryCrossentropy(name='binary cross entropy'),\n",
        "        tf.keras.metrics.BinaryIoU(name='binary IoU')\n",
        "    ]\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def create_regularized_LSTM_model(my_state, factor, rate, num_feat):\n",
        "  tf.random.set_seed(my_state)\n",
        "  model = tf.keras.Sequential([\n",
        "      #Dropout(rate),\n",
        "      tf.keras.layers.LSTM(256, input_shape=(num_feat, 1)),\n",
        "      #Dropout(rate),\n",
        "      #tf.keras.layers.LSTM(128, input_shape=(None, 1, 256)),\n",
        "      Dropout(rate),\n",
        "      tf.keras.layers.Dense(128, kernel_regularizer=l2(factor), activation='relu', name=\"relu1Layer\"),\n",
        "      Dropout(rate),\n",
        "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu2Layer\"),\n",
        "      Dropout(rate),\n",
        "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu3Layer\"),\n",
        "      Dropout(rate),\n",
        "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu4Layer\"),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid', name=\"sigmoidLayer\")\n",
        "      #tf.keras.layers.Dense(1, activation='relu', name=\"reluLayer\")\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.binary_crossentropy,\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "      metrics=[\n",
        "          tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "          tf.keras.metrics.Precision(name='precision'),\n",
        "          tf.keras.metrics.Recall(name='recall'),\n",
        "          tf.keras.metrics.BinaryCrossentropy(name='binary cross entropy'),\n",
        "          tf.keras.metrics.BinaryIoU(name='binary IoU')\n",
        "      ]\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def train_model(X_train_scaled, y_train, num_epochs):\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=checkpoint_dir, histogram_freq=1)\n",
        "  print(\"Training the neural network.. \")\n",
        "  history = model.fit(X_train_scaled, y_train, batch_size=32, epochs=num_epochs, callbacks=[cp_callback])\n",
        "  model.summary()\n",
        "  return history\n",
        "\n",
        "def visualize_performance(num_epochs, history):\n",
        "  import matplotlib.pyplot as plt\n",
        "  from matplotlib import rcParams\n",
        "  rcParams['figure.figsize'] = (18, 8)\n",
        "  rcParams['axes.spines.top'] = False\n",
        "  rcParams['axes.spines.right'] = False\n",
        "  plt.plot(\n",
        "      np.arange(1, num_epochs+1),\n",
        "      history.history['loss'], label='Loss'\n",
        "  )\n",
        "  plt.plot(\n",
        "      np.arange(1, num_epochs+1),\n",
        "      history.history['accuracy'], label='Accuracy'\n",
        "  )\n",
        "  plt.plot(\n",
        "      np.arange(1, num_epochs+1),\n",
        "      history.history['precision'], label='Precision'\n",
        "  )\n",
        "  plt.plot(\n",
        "      np.arange(1, num_epochs+1),\n",
        "      history.history['recall'], label='Recall'\n",
        "  )\n",
        "  plt.title('Evaluation metrics', size=20)\n",
        "  plt.xlabel('Epoch', size=14)\n",
        "  plt.legend();\n",
        "\n",
        "def evaluate_performance(model, X_test_scaled, y_test):\n",
        "  predictions = model.predict(X_test_scaled)\n",
        "  prediction_classes = [\n",
        "      1 if prob > 0.5 else 0 for prob in np.ravel(predictions)\n",
        "  ]\n",
        "  prediction_classes = [\n",
        "      1 if prob > 0.5 else 0 for prob in np.ravel(predictions)\n",
        "  ]\n",
        "  from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "  print(f'Accuracy: {accuracy_score(y_test, prediction_classes):.4f}')\n",
        "  print(f'Precision: {precision_score(y_test, prediction_classes):.4f}')\n",
        "  print(f'Recall: {recall_score(y_test, prediction_classes):.4f}')"
      ],
      "metadata": {
        "id": "JDlmwofnUR1T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res\n",
        "\n",
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "Pqf5Rp0frt9i"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_state = 22\n",
        "num_epochs = 50\n",
        "X_train_scaled, X_test_scaled, X_val_scaled, y_train, y_test, y_val = data_prep(my_state)\n",
        "# Create a callback that saves the model's weights\n",
        "checkpoint_path = \"/MSC_THESIS/MyDrive/School - Ryerson Graduate/MSC_THESIS/logs/23Jul10_update/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBsN-akFsrqa",
        "outputId": "63989ed2-d9fb-4dbd-e694-b26823685c31"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in the training set:  3240141\n",
            "Number of samples in the test set:  1012545\n",
            "Number of samples in the validation set:  810036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X_train_scaled.shape[1:]\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "kXic25n_sKBq",
        "outputId": "f36e9cc5-d6ff-4aa9-ba82-fbbd0e475e34"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-58f40c6d7f21>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model = build_model(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhead_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-d2b581be5a97>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout, mlp_dropout)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_transformer_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"channels_first\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-d2b581be5a97>\u001b[0m in \u001b[0;36mtransformer_encoder\u001b[0;34m(inputs, head_size, num_heads, ff_dim, dropout)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Normalization and Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     x = layers.MultiHeadAttention(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mkey_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     )(x, x)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/activation/softmax.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 )\n\u001b[1;32m    102\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Exception encountered when calling layer 'softmax' (type Softmax).\n\ntuple index out of range\n\nCall arguments received by layer 'softmax' (type Softmax):\n  • inputs=tf.Tensor(shape=(None, 4), dtype=float32)\n  • mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x_train_scaled,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "model.evaluate(X_test, y_test, verbose=1)"
      ],
      "metadata": {
        "id": "fvSc-YMPs2Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "  model.add(keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')"
      ],
      "metadata": {
        "id": "6l-VjOylqDgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_state = 22\n",
        "num_epochs = 50\n",
        "X_train_scaled, X_test_scaled, X_val_scaled, y_train, y_test, y_val = data_prep(my_state)\n",
        "# Create a callback that saves the model's weights\n",
        "checkpoint_path = \"/MSC_THESIS/MyDrive/School - Ryerson Graduate/MSC_THESIS/logs/23Jul10_update/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "#model = create_regularized_LSTM_model(my_state, 1e-5, 0.3, 19) #model creation and compilation\n",
        "#model.load_weights('/MSC_THESIS/MyDrive/School - Ryerson Graduate/MSC_THESIS/logs/23Jul09_Regularized_LSTM/cp-0097.ckpt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH0mQzkHTVJw",
        "outputId": "4c19c5f6-824b-4de4-d917-918b5ed24061"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in the training set:  3240141\n",
            "Number of samples in the test set:  1012545\n",
            "Number of samples in the validation set:  810036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    input_layer = keras.Input(shape=(512, 1))\n",
        "\n",
        "    x = layers.Conv1D(\n",
        "        filters=32, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\"\n",
        "    )(input_layer)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv1D(\n",
        "        filters=64, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\"\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv1D(\n",
        "        filters=128, kernel_size=5, strides=2, activation=\"relu\", padding=\"same\"\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv1D(\n",
        "        filters=256, kernel_size=5, strides=2, activation=\"relu\", padding=\"same\"\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv1D(\n",
        "        filters=512, kernel_size=7, strides=2, activation=\"relu\", padding=\"same\"\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv1D(\n",
        "        filters=1024, kernel_size=7, strides=2, activation=\"relu\", padding=\"same\"\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.Dense(4096, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Dense(\n",
        "        2048, activation=\"relu\", kernel_regularizer=keras.regularizers.L2()\n",
        "    )(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Dense(\n",
        "        1024, activation=\"relu\", kernel_regularizer=keras.regularizers.L2()\n",
        "    )(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(\n",
        "        128, activation=\"relu\", kernel_regularizer=keras.regularizers.L2()\n",
        "    )(x)\n",
        "    output_layer = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return keras.Model(inputs=input_layer, outputs=output_layer)"
      ],
      "metadata": {
        "id": "KE6AqV6xviVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kerastuner as kt\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    create_regularized_LSTM_model(my_state, 1e-5, 0.3, 19),\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=30,\n",
        "    hyperband_iterations=2)\n",
        "tuner.to_tensor()\n",
        "layer(tuner)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "oqmza_PvoZto",
        "outputId": "0f95dbdb-ce7f-4b22-b753-88f987018bcd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5646656514d2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkerastuner\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m tuner = kt.Hyperband(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcreate_regularized_LSTM_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0mmax_consecutive_failed_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_consecutive_failed_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         )\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypermodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             )\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mhypermodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Only populate initial space if not reloading.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_populate_initial_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m# Run in distributed mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeclare_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activate_all_conditions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_activate_all_conditions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# which does not have a `shape` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;34mf\"Inputs to a layer should be tensors. Got '{x}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;34mf\"(of type {type(x)}) as input for layer '{layer_name}'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got '<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7f04f93af6d0>' (of type <class 'keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters'>) as input for layer 'sequential_2'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize_performance(num_epochs, history)\n",
        "evaluate_performance(model, X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "YtVXKg8FT4Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(1)[0]"
      ],
      "metadata": {
        "id": "kTQlw3FTm8Uy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}